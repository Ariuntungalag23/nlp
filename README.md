# 1. Dataset-ийн танилцуулга

Энэхүү судалгаанд sentiment analysis хийх зорилгоор IMDB Large Movie Review Dataset-ийг ашигласан. Уг датасет нь кино шүүмжүүдээс бүрдэх бөгөөд sentiment analysis-ийн судалгаанд өргөн хэрэглэгддэг стандарт benchmark датасетүүдийн нэг гэж тооцогддог. IMDB датасет нь анх Maas et al. (2011) судалгаанд танилцуулагдсан бөгөөд түүнээс хойш уламжлалт машин сургалт, гүн сургалт, transformer-based загваруудын гүйцэтгэлийг харьцуулахад ашиглагдаж ирсэн.

Датасет нь нийт 50,000 кино шүүмжээс бүрдэх ба эдгээр нь сургалтын болон тестийн хэсэгт тэнцүүгээр хуваагдсан байдаг. Өөрөөр хэлбэл, 25,000 шүүмжийг сургалтанд, үлдсэн 25,000 шүүмжийг загварын гүйцэтгэлийг шалгахад ашигладаг. Мөн sentiment шошго нь positive болон negative гэсэн хоёр ангитай бөгөөд анги бүр ижил тооны жишээ агуулдаг тул датасет нь ангиллын хувьд тэнцвэртэй гэж үзэгддэг.

IMDB кино шүүмжүүд нь харьцангуй урт текстүүдээс бүрддэг нь уг датасетийн нэг онцлог юм. Дундаж нэг шүүмж нь хэдэн арван өгүүлбэр агуулдаг бөгөөд энэ нь sentiment analysis хийх үед зөвхөн үгсийн давтамж бус, харин үгийн дараалал, өгүүлбэр хоорондын хамаарал болон нийт баримтын контекстийг загварчлах шаардлагыг бий болгодог. Иймээс IMDB датасет нь урт текст дээр ажиллах чадвартай загваруудын давуу болон сул талыг судлахад тохиромжтой орчин болдог.

Түүнчлэн уг датасет нь анхнаасаа хатуу шүүлтүүрээр ангилагдсан шүүмжүүдийг агуулдаг бөгөөд neutral ангилал байхгүй, зөвхөн тодорхой positive эсвэл negative sentiment илэрхийлсэн баримтуудаас бүрддэг. Энэ нь binary sentiment classification асуудлыг цэвэр хэлбэрээр судлах боломж олгодог бөгөөд ангиллын үр дүнг тайлбарлахад илүү ойлгомжтой болгодог.

Ерөнхийд нь дүгнэвэл, IMDB Large Movie Review Dataset нь хэмжээ, бүтэц, ангиудын тэнцвэр болон текстийн уртаараа sentiment analysis-ийн судалгаанд өргөн ашиглагддаг бөгөөд энэхүү судалгаанд ашигласан загваруудын гүйцэтгэлийг үнэлэхэд тохиромжтой датасет юм.

## 1.1 Maas et al. (2011) Learning Word Vectors for Sentiment Analysis [1]

1.1.1 Судалгааны зорилго

Maas et al. (2011) нь sentiment analysis-д өргөн хэрэглэгдэж байсан bag-of-words болон n-gram суурь аргууд нь үгийн семантик утга болон сэтгэл хөдлөлийн чиглэлийг хангалттай илэрхийлж чаддаггүй сул талтайг онцолж, тухайн асуудлыг шийдвэрлэх зорилгоор sentiment мэдээлэл шингээсэн word embedding сургах боломжийг судалсан. Судалгааны үндсэн зорилго нь үгсийн vector representation-д polarity мэдээллийг оруулснаар кино шүүмжийн sentiment ангиллын гүйцэтгэл хэрхэн сайжрахыг IMDB Large Movie Review Dataset дээр туршилтаар баталгаажуулах явдал байв.

1.1.2 Ашигласан tokenizer

Энэхүү судалгаанд текстийг word-level түвшинд задлах энгийн tokenizer ашигласан бөгөөд whitespace-д суурилсан tokenization хийж, үг бүрийг тусдаа token болгон авч үзсэн. Судлаачид stopword устгал хийхээс татгалзсан нь “not”, “never” зэрэг сөрөг утга агуулсан үгс sentiment classification-д чухал нөлөөтэй гэж үзсэнтэй холбоотой.

1.1.3 Ашигласан embedding

Судалгаанд sentiment-specific word embedding ашигласан бөгөөд эдгээр embedding-ийг unsupervised language modeling болон supervised sentiment label-ийг хослуулсан сургалтын аргаар сургаж, үг бүрт эерэг болон сөрөг polarity-ийн мэдээллийг тусгасан вектор төлөөлөл үүсгэсэн.

1.1.4 Ашигласан загвар

Үүсгэсэн word embedding-үүдийг ашиглан баримт бүрийн вектор төлөөллийг гаргаж, эдгээрийг Logistic Regression суурьтай linear classifier-д оруулан sentiment ангилал гүйцэтгэсэн.

1.1.5 Ашигласан үнэлгээ, үр дүн

IMDB датасет нь positive болон negative анги тэнцүүтэй тул загварын гүйцэтгэлийг үнэлэхэд accuracy хэмжүүрийг ашигласан бөгөөд sentiment-aware embedding бүхий загвар нь ойролцоогоор 88–89 хувийн accuracy үзүүлж, unigram болон bigram суурь аргуудаас илүү сайн үр дүн гаргасан нь embedding-ийн ач холбогдлыг тодорхой харуулсан.

## 1.2 Kim (2014) Convolutional Neural Networks for Sentence Classification[2]


1.2.1 Судалгааны зорилго
Kim (2014) нь convolutional neural network архитектур нь текст доторх local n-gram хэв шинжийг автоматаар сурч чаддаг тул sentiment classification зэрэг текст ангиллын асуудалд үр дүнтэй ашиглагдаж болох эсэхийг судлах зорилготой байсан. Судалгааны хүрээнд CNN загвар нь уламжлалт machine learning аргуудаас хэр зэрэг давж чадахыг IMDB датасет дээр туршиж үзсэн.

1.2.2 Ашигласан tokenizer

Судалгаанд word-level tokenizer ашиглан текстийг үг болгон задлаж, дараа нь бүх өгөгдлийг fixed-length sequence хэлбэрт оруулж, богино баримтыг padding ашиглан жигдрүүлсэн.

1.2.3 Ашигласан embedding

CNN загварт pretrained Word2Vec embedding ашигласан бөгөөд embedding-ийг өөрчлөлтгүй (static) болон сургалтын явцад шинэчлэгддэг (non-static) хоёр хувилбараар туршиж, fine-tuning-ийн нөлөөг харьцуулан судалсан.

1.2.4 Ашигласан загвар

Судалгаанд нэг convolutional давхаргатай CNN загвар ашиглаж, өөр өөр хэмжээтэй filter-үүдээр текст доторх n-gram шинж чанаруудыг гарган авч, max-pooling ашиглан баримтын түвшний representation үүсгэсэн.

1.2.5 Ашигласан үнэлгээ, үр дүн

IMDB датасет нь стандарт benchmark тул accuracy хэмжүүрийг ашиглан гүйцэтгэлийг үнэлсэн бөгөөд CNN загвар нь ойролцоогоор 90–90.5 хувийн accuracy үзүүлж, deep learning загварууд текст ангилалд өндөр үр ашигтай болохыг баталсан.

## 1.3 Johnson & Zhang (2015) Effective Use of Word Order for Text Categorization with CNNs[3]

1.3.1 Судалгааны зорилго

Johnson ба Zhang (2015) нь стандарт CNN загварууд нь урт баримтын хувьд үгийн дарааллын мэдээллийг бүрэн ашиглаж чаддаггүй сул талтай гэж үзэж, үгийн дарааллыг илүү сайн хадгалах зорилготой region-based CNN архитектурыг санал болгосон. Тэдний судалгааны зорилго нь уг архитектур урт кино шүүмжүүдээс бүрдэх IMDB датасет дээр хэр үр дүнтэй ажиллахыг шалгах явдал байв.

1.3.2 Ашигласан tokenizer

Судалгаанд word-level tokenizer ашиглаж, текстийг үг болгон задлаад sliding window зарчмаар үгсийн бүс (region) үүсгэн авч үзсэн.

1.3.3 Ашигласан embedding

Үг бүрийг эхний ээлжинд one-hot representation хэлбэрээр авч, дараа нь embedding projection layer ашиглан dense vector representation болгон хувиргасан.

1.3.4 Ашигласан загвар

Region-based CNN загвар нь эдгээр үгсийн бүсүүд дээр convolution үйлдэл хийж, баримтын түвшний шинж чанарыг илүү үр дүнтэй гарган авсан.

1.3.5 Ашигласан үнэлгээ, туршилтын үр дүн

IMDB датасет дээр accuracy хэмжүүр ашиглан үнэлэхэд region-based CNN загвар нь ойролцоогоор 91–92 хувийн accuracy үзүүлж, стандарт CNN болон n-gram суурь аргуудаас илүү гүйцэтгэлтэй болохыг харуулсан.

## 1.4 Dai & Le (2015) Semi-supervised Sequence Learning[4] 

1.4.1 Судалгааны зорилго

Dai ба Le (2015) нь их хэмжээний label-гүй текст өгөгдлийг ашиглан sequence model-ийг урьдчилан сургах нь supervised sentiment classification-ийн гүйцэтгэлийг сайжруулж чадах эсэхийг судлах зорилготой байсан. Тэд language model pretraining-ийг LSTM загварт ашиглах шинэ хандлагыг санал болгосон.

1.4.2 Ашигласан tokenizer

Судалгаанд word-level tokenizer ашиглаж, текстийг дараалсан үгсийн sequence хэлбэрээр авч үзсэн.

1.4.3 Ашигласан embedding

Embedding-ийг тусгайлан урьдчилан бэлдээгүй бөгөөд pretraining болон fine-tuning явцад LSTM загвартай хамт сурсан task-specific embedding ашигласан.

1.4.4 Ашигласан загвар

Language model байдлаар урьдчилан сурсан LSTM загварыг дараа нь sentiment classification task-д fine-tune хийж ашигласан.

1.4.5 Ашигласан үнэлгээ, туршилтын үр дүн

IMDB датасет дээр accuracy хэмжүүрээр үнэлэхэд semi-supervised LSTM загвар нь ойролцоогоор 92–93 хувийн accuracy үзүүлж, зөвхөн supervised сургалттай загвараас илүү үр дүнтэй болохыг харуулсан.


## 1.5 Tang et al. (2015) Document Modeling with Gated Recurrent Neural Network[5] 

1.5.1 Судалгааны зорилго

Tang et al. (2015) нь LSTM загварын бүтэц харьцангуй төвөгтэй, тооцооллын зардал ихтэй байдаг сул талыг багасгах зорилгоор GRU архитектурыг ашиглан баримтын түвшний sentiment analysis хийх боломжийг судалсан.

1.5.2 Ашигласан tokenizer

Судалгаанд word-level tokenizer ашиглаж, кино шүүмжүүдийг үгсийн дараалал хэлбэрээр загварчилсан.

1.5.3 Ашигласан embedding

Word embedding-ийг random initialization ашиглан эхлүүлж, сургалтын явцад загвартай хамт сурсан.

1.5.4 Ашигласан загвар

GRU суурьтай recurrent neural network ашиглан баримтын дараалсан мэдээллийг загварчилж, эцсийн hidden state-ийг sentiment ангилалд ашигласан.

1.5.5 Ашигласан үнэлгээ, туршилтын үр дүн

IMDB датасет дээр accuracy хэмжүүр ашиглан үнэлэхэд GRU загвар нь ойролцоогоор 90–91 хувийн accuracy үзүүлж, LSTM-тэй ойролцоо гүйцэтгэлтэй атлаа илүү энгийн бүтэцтэй болохыг харуулсан.

## 1.6 Zhang et al. (2015) Character-level Convolutional Networks for Text Classification[6]

1.6.1 Судалгааны зорилго

Zhang et al. (2015) нь үг дээр суурилсан tokenization нь үгийн алдаа, slang, domain-specific илэрхийллүүдийг боловсруулахад хязгаарлагдмал байж болохыг онцолж, текстийг зөвхөн character түвшинд төлөөлөх замаар sentiment classification хийх боломжийг судалсан. Судалгааны зорилго нь word-level preprocessing-оос бүрэн татгалзсан нөхцөлд deep learning загварууд хэр үр дүнтэй ажиллаж чадахыг IMDB зэрэг томоохон датасетууд дээр турших явдал байв.

1.6.2 Ашигласан tokenizer

Судалгаанд character-level tokenizer ашиглаж, текстийг нэг бүрчлэн тэмдэгтүүдэд задлан fixed-length character sequence хэлбэрээр загварчилсан.

1.6.3 Ашигласан embedding

Тэмдэгт бүрийг random initialization бүхий character embedding хэлбэрээр төлөөлж, сургалтын явцад эдгээр embedding-үүдийг CNN загвартай хамт сурсан.

1.6.4 Ашигласан загвар

Олон convolutional давхаргаас бүрдэх deep CNN архитектур ашиглаж, temporal max-pooling аргаар character-level шинж чанаруудыг баримтын түвшинд нэгтгэсэн.

1.6.5 Ашигласан үнэлгээ, туршилтын үр дүн

IMDB датасет дээр accuracy хэмжүүрээр үнэлэхэд character-level CNN загвар нь ойролцоогоор 87–88 хувийн accuracy үзүүлсэн бөгөөд word-level загваруудаас бага зэрэг доогуур байсан ч tokenization шаардлагагүй хандлагын боломжийг харуулсан.

## 1.7 Howard & Ruder (2018) Universal Language Model Fine-tuning (ULMFiT)[7]

1.7.1 Судалгааны зорилго

Howard ба Ruder (2018) нь NLP салбарт computer vision-тэй адил transfer learning өргөн ашиглагдаж болохыг харуулах зорилгоор Universal Language Model Fine-tuning буюу ULMFiT аргыг санал болгосон. Тэдний судалгааны үндсэн зорилго нь language model-ийг их хэмжээний корпус дээр урьдчилан сургаад, дараа нь sentiment analysis зэрэг downstream task-д fine-tune хийх нь гүйцэтгэлийг хэрхэн сайжруулж болохыг харуулах явдал байв.

1.7.2 Ашигласан tokenizer

Судалгаанд subword түвшний tokenizer ашиглаж, үгсийг хэсэгчлэн задлах замаар out-of-vocabulary асуудлыг багасгасан.

1.7.3 Ашигласан embedding

Pretrained language model-оос гарсан contextual embedding-үүдийг ашигласан бөгөөд эдгээр embedding нь fine-tuning явцад task-д нийцүүлэн шинэчлэгдсэн.

1.7.4 Ашигласан загвар


AWD-LSTM архитектурт суурилсан language model ашиглаж, discriminative fine-tuning болон gradual unfreezing зэрэг стратегиудыг хэрэглэсэн.

1.7.5 Ашигласан үнэлгээ, туршилтын үр дүн

IMDB датасет дээр accuracy хэмжүүрээр үнэлэхэд ULMFiT загвар нь ойролцоогоор 94–95 хувийн accuracy үзүүлж, тухайн үедээ state-of-the-art гүйцэтгэлд хүрсэн.

## 1.8 Devlin et al. (2019) BERT: Pre-training of Deep Bidirectional Transformers[8] 

1.8.1 Судалгааны зорилго

Devlin et al. (2019) нь үгийн embedding-ийг зөвхөн нэг чиглэлтэй контекстээр бус, хоёр чиглэлтэй контекстээр сурах боломжийг олгох 
зорилгоор BERT загварыг санал болгосон. Судалгааны зорилго нь bidirectional Transformer ашиглан контекстэд мэдрэмтгий representation сургаж, sentiment analysis зэрэг олон NLP даалгаварт ерөнхийлөн ашиглах явдал байв.

1.8.2 Ашигласан tokenizer

Судалгаанд WordPiece tokenizer ашиглаж, үгсийг subword нэгжүүдэд задлан out-of-vocabulary асуудлыг үр дүнтэй шийдвэрлэсэн.

1.8.3 Ашигласан embedding

Transformer encoder-оос гарсан contextual embedding-үүдийг ашигласан бөгөөд нэг ижил үг өөр өөр контекстэд өөр embedding-тэй болж чаддаг.

1.8.4 Ашигласан загвар

BERT-base болон BERT-large хувилбаруудыг ашиглаж, pretraining дараа нь sentiment classification task-д fine-tune хийсэн.

1.8.5 Ашигласан үнэлгээ, туршилтын үр дүн

IMDB датасет дээр fine-tuned BERT загварууд нь ойролцоогоор 94–95 хувийн accuracy үзүүлж, өмнөх deep learning загваруудаас давсан 
гүйцэтгэлтэй болохыг харуулсан.

## 1.9 Radford et al. (2018) Generative Pre-training (GPT)[9]

1.9.1 Судалгааны зорилго

Radford et al. (2018) нь unsupervised language model pretraining нь downstream NLP даалгавруудад хэрхэн эерэг нөлөө үзүүлж болохыг судлах зорилгоор GPT загварыг санал болгосон. Тэдний судалгааны зорилго нь generative Transformer архитектур ашиглан текстийн ерөнхий мэдлэгийг сургаж, дараа нь sentiment analysis-д ашиглах явдал байв.

1.9.2 Ашигласан tokenizer

Судалгаанд Byte Pair Encoding ашиглаж, subword түвшний tokenization хийсэн.

1.9.3 Ашигласан embedding

Transformer decoder-оос гарсан contextual embedding-үүдийг ашигласан бөгөөд эдгээр embedding нь pretraining явцад сурсан хэлний мэдлэгийг агуулсан.

1.9.4 Ашигласан загвар

Transformer decoder архитектурт суурилсан GPT загварыг ашиглаж, sentiment classification task-д fine-tune хийсэн.

1.9.5 Ашигласан үнэлгээ, туршилтын үр дүн

IMDB датасет дээр GPT загвар нь ойролцоогоор 91–92 хувийн accuracy үзүүлж, pretraining стратегийн үр ашгийг баталсан.

## 1.10 Yang et al. (2016) Hierarchical Attention Networks[10] 

1.10.1 Судалгааны зорилго

Yang et al. (2016) нь урт баримт нь үг болон өгүүлбэрийн шаталсан бүтэцтэй байдаг онцлогийг харгалзан үзэхгүйгээр текст ангилах нь мэдээллийн алдагдалд хүргэдэг гэж үзэж, hierarchical бүтэцтэй attention-based загварыг санал болгосон. Судалгааны зорилго нь баримтын дотоод бүтцийг загварчилснаар sentiment classification-ийн гүйцэтгэлийг сайжруулах явдал байв.

1.10.2 Ашигласан tokenizer

Судалгаанд word-level tokenizer ашиглаж, текстийг өгүүлбэр болон үгсийн түвшинд сегментчилсэн.

1.10.3 Ашигласан embedding

Word embedding-ийг ашиглан үгсийг вектор хэлбэрт төлөөлсөн бөгөөд эдгээр embedding-үүдийг attention механизмтай хамтатган хэрэглэсэн.

1.10.4 Ашигласан загвар

Үг болон өгүүлбэрийн түвшинд тус тусдаа recurrent neural network ашиглаж, attention механизмын тусламжтайгаар баримтын хамгийн чухал хэсгүүдийг онцолсон.

1.10.5 Ашигласан үнэлгээ, туршилтын үр дүн

IMDB датасет дээр accuracy хэмжүүрээр үнэлэхэд Hierarchical Attention Network загвар нь ойролцоогоор 91–92 хувийн accuracy үзүүлж, урт текстийн бүтцийг загварчлах нь sentiment analysis-д үр дүнтэй болохыг харуулсан.

## 1.11 Судалгаануудын үр дүнгийн нэгтгэл

| № | Судалгаа | Tokenizer | Embedding | Загвар | Үнэлгээ | IMDB дээрх үр дүн |
|---|-----------|-----------|-----------|--------|---------|------------------|
| 1 | Maas et al. (2011) | Word-level | Sentiment-aware word vectors | Logistic Regression | Accuracy | 0.88–0.89 |
| 2 | Kim (2014) | Word-level | Word2Vec (static / non-static) | CNN | Accuracy | 0.90–0.905 |
| 3 | Johnson & Zhang (2015) | Word-level | One-hot - projection | Region-based CNN | Accuracy | 0.91–0.92 |
| 4 | Dai & Le (2015) | Word-level | Task-specific embedding | Semi-supervised LSTM | Accuracy | 0.92–0.93 |
| 5 | Tang et al. (2015) | Word-level | Learned embedding | GRU | Accuracy | 0.90–0.91 |
| 6 | Zhang et al. (2015) | Character-level | Character embedding | Deep CNN | Accuracy | 0.87–0.88 |
| 7 | Howard & Ruder (2018) | Subword | Contextual LM embedding | AWD-LSTM (ULMFiT) | Accuracy | 0.94–0.95 |
| 8 | Devlin et al. (2019) | WordPiece | Contextual Transformer embedding | BERT (fine-tuned) | Accuracy | 0.94–0.95 |
| 9 | Radford et al. (2018) | BPE | Contextual Transformer embedding | GPT (fine-tuned) | Accuracy | 0.91–0.92 |
| 10 | Yang et al. (2016) | Word-level | Word embedding + attention | Hierarchical Attention Network | Accuracy | 0.91–0.92 |

# 2. Онолын хэсэг 

Энэхүү бүлэгт уг судалгаанд ашигласан текст боловсруулах арга, embedding техникүүд, ангилах загварууд болон үнэлгээний хэмжүүрүүдийн онолын үндсийг тайлбарлана. Эдгээр аргууд нь sentiment analysis асуудлыг шийдвэрлэхэд өргөн хэрэглэгддэг бөгөөд тухайн аргуудын математик үндэслэл нь туршилтын үр дүнг тайлбарлахад чухал ач холбогдолтой.

## 2.1 Sentiment Analysis-ийн онолын үндэс

Sentiment analysis нь өгөгдсөн текст x-ээс түүний илэрхийлж буй сэтгэл хөдлөлийн чиглэлийг тодорхойлох ангиллын асуудал юм. Энэхүү судалгаанд sentiment ангиллыг хоёр ангит хэлбэрээр тодорхойлсон бөгөөд зорилго нь дараах функцыг сурах явдал болно.



Энд x нь кино шүүмж текст, харин y=1 нь эерэг, y=0 нь сөрөг sentiment-ийг илэрхийлнэ. Текст өгөгдөл нь анхдагч байдлаар шууд тоон загварт ашиглагдах боломжгүй тул түүнийг вектор хэлбэрт хөрвүүлэх шаардлагатай.

## 2.2 Текстийн урьдчилсан боловсруулалтын онол

Текстийн урьдчилсан боловсруулалт нь noise багасгах, feature space-ийг цэгцлэх үндсэн зорилготой. Lowercasing нь үгсийн ялгаатай бичлэгээс үүдэх хиймэл ялгааг арилгаж, HTML tag болон alphabet бус тэмдэгтийг устгах нь утга агуулаагүй элементийг хасахад чиглэнэ. Tokenization нь текстийг дараалсан үгсийн олонлог болгон хувиргах бөгөөд энэхүү судалгаанд word-level tokenization ашигласан. Stopword устгал нь давтамж өндөр боловч мэдээлэл багатай үгсийг хасаж, загварын сурах чадварыг сайжруулахад чиглэсэн.

## 2.3 TF-IDF embedding

TF-IDF нь үгийн чухал байдлыг статистик аргаар тодорхойлох арга юм. Нэг баримт d-д агуулагдах үг t-ийн TF-IDF жин нь дараах байдлаар тодорхойлогдоно.







Энд f(t,d) нь үг t-ийн баримт d-д давтагдсан тоо, N нь нийт баримтын тоо, DF(t) нь тухайн үгийг агуулсан баримтын тоо юм. TF-IDF representation нь sparse шинж чанартай бөгөөд үгийн дарааллыг хадгалахгүй ч sentiment analysis-д хүчтэй суурь арга болдог.

## 2.4 Word2Vec embedding

Word2Vec нь үгсийн семантик болон синтакс харилцааг бага хэмжээст dense вектор орон зайд загварчилдаг нейрон сүлжээ суурьтай embedding арга юм. Word2Vec нь тухайн үгсийн хамтран орших хэв шинжид тулгуурлан “ойролцоо орчинд ашиглагддаг үгс ижил утгатай байна” гэсэн тархмал таамаглалыг ашигладаг. Энэхүү судалгаанд Word2Vec-ийн CBOW болон Skip-gram гэсэн хоёр үндсэн архитектурыг тус тусад нь ашиглан туршсан.

2.4.1 Continuous Bag-of-Words (CBOW)

Continuous Bag-of-Words архитектур нь тухайн үгийн орчны үгсийг ашиглан төв үгийг таамаглах зарчимд суурилдаг. Өөрөөр хэлбэл, өгөгдсөн контекст C = \{w_{t-c}, \dots, w_{t-1}, w_{t+1}, \dots, w_{t+c}\}-оос төв үг w_t-ийн магадлалыг сурдаг. CBOW загварын сургалтын зорилгын функц нь дараах байдлаар тодорхойлогдоно.

 

Энд T нь сургалтын өгөгдөл дэх нийт үгсийн тоо, c нь контекст цонхны хэмжээ юм. Орчны үгсийн embedding-үүдийг дундажлан нэг вектор болгон ашиглаж, төв үгийн магадлалыг softmax функцээр тооцоолно.



CBOW загвар нь тооцооллын хувьд хөнгөн бөгөөд сургалтын хурд өндөр байдаг давуу талтай. Гэвч орчны үгсийг нэгтгэх явцад мэдээлэл алдагдах боломжтой тул ховор боловч sentiment агуулсан үгсийн семантик ялгааг нарийн барих чадвар харьцангуй сул байж болно.

2.4.2 Skip-gram

Skip-gram архитектур нь CBOW-оос эсрэг чиглэлтэй ажилладаг бөгөөд тухайн төв үгээс түүний орчны үгсийг таамаглах зорилготой. Энэ нь өгөгдсөн төв үг w_t-ийн хувьд контекст доторх үг бүр w_{t+j}-ийн магадлалыг тооцоолох байдлаар сургалт явагдана. Skip-gram загварын зорилгын функц дараах байдлаар илэрхийлэгдэнэ.



Энд c нь контекст цонхны хэмжээ юм. Орчны үгийн магадлал нь softmax функц ашиглан дараах байдлаар тодорхойлогдоно.



Skip-gram загвар нь CBOW-оос илүү нарийн семантик ялгааг сурч чаддаг бөгөөд ялангуяа ховор үгсийн embedding-ийг илүү сайн төлөөлөх давуу талтай. Иймээс sentiment analysis-д чухал нөлөөтэй, цөөн давтамжтай үгсийг илүү сайн барих чадвартай гэж үзэгддэг.

## 2.5 Transformer суурьтай BERT загварын онол

BERT (Bidirectional Encoder Representations from Transformers) нь Transformer архитектур дээр суурилсан, контекстэд мэдрэмтгий текстийн төлөөлөл үүсгэх загвар юм. Уламжлалт word embedding-үүдээс ялгаатай нь BERT нь үгийг зөвхөн нэг чиглэлтэй контекстээр бус, хоёр чиглэлтэй буюу тухайн үгийн өмнөх болон дараах бүх үгсийн мэдээллийг ашиглан төлөөлдөг. Энэ нь sentiment analysis зэрэг контекст ихээхэн ач холбогдолтой даалгаварт илүү нарийн ялгаа барих боломж олгодог.

Transformer архитектурын үндсэн бүрэлдэхүүн хэсэг нь self-attention механизм бөгөөд дараалал дахь элементүүдийн хоорондын хамаарлыг зэрэг тооцоолдог. Scaled dot-product attention дараах байдлаар тодорхойлогдоно.



Энд Q, K, V нь тус тус query, key, value матрицууд бөгөөд d_k нь key-ийн хэмжээс юм. Энэхүү attention механизм нь үг бүрийн representation-ийг тухайн өгүүлбэр дэх бусад бүх үгстэй харилцан хамааралтайгаар шинэчилдэг.

BERT нь олон Transformer encoder давхаргаас бүрдэх ба урьдчилсан сургалтын үе шатанд masked language modeling болон next sentence prediction гэсэн зорилтуудыг ашиглан ерөнхий хэлний мэдлэг сурдаг. Sentiment classification хийх үед урьдчилан сурсан BERT загварыг тухайн даалгаварт fine-tune хийж ашигладаг бөгөөд баримтын түвшний төлөөллийг тусгай [CLS] token-ийн гаралтаар илэрхийлдэг.



Эцсийн ангиллыг дараах байдлаар гүйцэтгэнэ.



Энэхүү судалгаанд BERT-base болон ALBERT загваруудыг ашигласан бөгөөд эдгээрийг embedding хэлбэрээр гарган авч, цаашдын ангилагч загваруудтай хослуулан туршсан.

## 2.6 Ашигласан загваруудын онол

2.6.1 Logistic Regression

Logistic Regression нь хоёр ангит ангиллын асуудалд өргөн хэрэглэгддэг шугаман загвар бөгөөд оролтын вектор x \in \mathbb{R}^d-д харгалзах эерэг ангид хамаарах магадлалыг sigmoid функцээр илэрхийлдэг.



Загварыг сургах явцад дараах логистик алдагдлын функцийг хамгийн бага болгохыг зорьдог.



2.6.2 Random Forest

Random Forest нь олон decision tree-ийг нэгтгэсэн ensemble загвар бөгөөд сургалтын өгөгдлийг bootstrap sampling ашиглан олон янзаар хувааж, тус бүр дээр decision tree сургадаг. Эцсийн ангиллыг бүх модны гаргалтын олонхийн саналаар тодорхойлно.



Энэхүү загвар нь non-linear харилцааг барих чадвартай боловч өндөр хэмжээст sparse feature-тэй орчинд гүйцэтгэл тогтворгүй байж болно.

2.6.3 AdaBoost

AdaBoost нь weak learner-үүдийг дараалж нэгтгэх boosting арга бөгөөд өмнөх шатанд буруу ангилагдсан жишээнд илүү их жин өгч дараагийн learner-ийг сургадаг.

 

Энд  нь m-р learner-ийн алдаа юм.

2.6.4 Long Short-Term Memory (LSTM)

LSTM нь recurrent neural network-ийн нэг төрөл бөгөөд урт хугацааны хамаарлыг хадгалах зорилготой. LSTM нэгжийн үндсэн тооцооллууд дараах байдлаар өгөгдөнө.









LSTM нь текстийн дарааллын мэдээллийг ашиглах боломж олгодог тул урт кино шүүмжүүдийг загварчлахад тохиромжтой.

## 2.7 Үнэлгээний аргуудын онол

Энэхүү судалгаанд sentiment classification загваруудын гүйцэтгэлийг үнэлэх зорилгоор Accuracy, Precision, Recall, F1-score гэсэн стандарт үнэлгээний хэмжүүрүүдийг ашигласан. Эдгээр хэмжүүрүүдийг embedding болон загвар бүрийн хувьд ижил байдлаар тооцоолсноор үр дүнг шударгаар харьцуулах боломж бүрдсэн.

Sentiment analysis нь хоёр ангит ангиллын асуудал тул үнэлгээг confusion matrix-д тулгуурлан тодорхойлно. Энд true positive (TP) нь эерэг sentiment-ийг зөв ангилсан тохиолдол, true negative (TN) нь сөрөг sentiment-ийг зөв ангилсан тохиолдол, false positive (FP) нь сөрөг шүүмжийг эерэг гэж буруу ангилсан тохиолдол, false negative (FN) нь эерэг шүүмжийг сөрөг гэж буруу ангилсан тохиолдлыг илэрхийлнэ.

2.7.1 Accuracy

Accuracy нь нийт жишээнүүдээс хэчнээн хувийг зөв ангилсныг илэрхийлдэг бөгөөд дараах байдлаар тодорхойлогдоно.





IMDB датасет нь positive болон negative ангиудын хувьд тэнцвэртэй тул accuracy нь загварын ерөнхий гүйцэтгэлийг үнэлэхэд тохиромжтой хэмжүүр гэж үзэгддэг. Иймээс энэхүү судалгаанд accuracy-г үндсэн гүйцэтгэлийн үзүүлэлт болгон ашигласан.

2.7.2 Precision

Precision нь эерэг гэж таамагласан жишээнүүдээс үнэхээр эерэг байсан хувь хэмжээг илэрхийлнэ.



Энэхүү хэмжүүр нь загварын positive ангиллын найдвартай байдлыг харуулдаг бөгөөд sentiment analysis-д буруу эерэг ангилал хийх нь үр дүнгийн тайлбарлалтад сөргөөр нөлөөлж болох тул precision нь чухал үзүүлэлт болдог.

2.7.3 Recall

Recall нь бодит эерэг жишээнүүдээс загвар хэчнээн хувийг зөв илрүүлснийг харуулна.



Recall нь загварын мэдрэмж (sensitivity)-ийг илэрхийлдэг бөгөөд эерэг sentiment-ийг алдах эрсдэлийг үнэлэхэд ашиглагддаг.

2.7.4 F1-score

F1-score нь precision болон recall-ийн хоорондын тэнцвэрийг илэрхийлдэг нийлмэл хэмжүүр юм.



Accuracy өндөр боловч precision эсвэл recall бага байх боломжтой тул F1-score нь загварын гүйцэтгэлийг илүү бодитой үнэлэх боломж олгодог.

2.7.5 Deep learning загварын үнэлгээ

LSTM болон Transformer суурьтай загваруудын хувьд cross-validation хийх нь тооцооллын зардал өндөр тул тухайн туршилтад prediction-д суурилсан үнэлгээ ашигласан. Загварын гаралтыг binary ангилалд хөрвүүлж, дээр дурдсан дөрвөн хэмжүүрийг шууд тооцоолсон. Ийм үнэлгээ нь deep learning загваруудын гүйцэтгэлийг практик нөхцөлд үнэлэхэд түгээмэл хэрэглэгддэг.

2.7.6 Үнэлгээний хэсгийн нэгтгэл

Энэхүү судалгаанд ашигласан үнэлгээний хэмжүүрүүд нь загварын ерөнхий гүйцэтгэл, ангиллын найдвартай байдал болон мэдрэмжийг цогцоор нь үнэлэх боломж олгосон. Accuracy нь суурь харьцуулалт хийхэд тохиромжтой бол precision, recall болон F1-score нь загваруудын давуу болон сул талыг нарийвчлан илрүүлэхэд чухал үүрэг гүйцэтгэсэн.

# 3. Туршилт 

Энэхүү судалгаанд IMDB Large Movie Review Dataset дээр sentiment classification хийх зорилгоор олон төрлийн текстийн төлөөлөл болон ангилах загваруудыг ашиглан туршилтуудыг системтэйгээр гүйцэтгэлээ. Туршилтын үндсэн зорилго нь өөр өөр embedding аргууд болон загваруудын гүйцэтгэлийг ижил нөхцөлд харьцуулан судалж, аль хослол нь тухайн асуудалд илүү тохиромжтой болохыг тодорхойлох явдал байв.

Туршилтын эхний шатанд датасетийг урьдчилсан боловсруулалт хийж, бүх текстийг жижиг үсэгт шилжүүлэх, HTML tag болон тэмдэгтийг устгах, word-level tokenization хийх, мөн stopword-уудыг хасах зэрэг алхмуудыг хэрэгжүүлсэн. Үүний дараа өгөгдлийг сургалтын зориулалтаар санамсаргүй байдлаар дэд хэсэг болгон сонгож, бүх туршилтад ижил өгөгдлийг ашигласнаар үр дүнг шударгаар харьцуулах нөхцөлийг бүрдүүлсэн.

Дараагийн шатанд текстийн төлөөллийг үүсгэх зорилгоор TF-IDF, Word2Vec болон Transformer суурьтай embedding аргуудыг ашигласан. TF-IDF embedding-ийг unigram болон n-gram тохиргоогоор гаргаж, эдгээрийг уламжлалт машин сургалтын загваруудтай хослуулан туршсан. Word2Vec-ийн хувьд CBOW болон Skip-gram архитектуруудаар үгсийн embedding сургаж, баримтын түвшний representation-ийг үг бүрийн embedding-ийн дундаж вектороор илэрхийлсэн. Transformer суурьтай embedding-үүдийн хувьд BERT-base болон ALBERT загваруудыг ашиглан контекстэд мэдрэмтгий төлөөлөл гарган авсан.

Ангилах загваруудын хувьд Logistic Regression, Random Forest, AdaBoost болон LSTM загваруудыг ашигласан. Logistic Regression, Random Forest болон AdaBoost загваруудад параметрийн олон хувилбарыг системтэйгээр туршиж, загварын гүйцэтгэлийг илүү тогтвортой үнэлэх зорилгоор гурван хуваалттай cross-validation хэрэглэсэн. LSTM загварыг Word2Vec болон TF-IDF embedding-тэй хослуулан sequence хэлбэрээр сургаж, сургалтын дараах prediction-д тулгуурлан үнэлгээ хийсэн.

Туршилтын бүх загваруудыг Accuracy, Precision, Recall болон F1-score гэсэн үнэлгээний хэмжүүрүүдээр үнэлсэн бөгөөд эдгээр хэмжүүрүүдийг ашигласнаар загварын ерөнхий гүйцэтгэл төдийгүй ангиллын найдвартай байдал болон мэдрэмжийг нарийвчлан шинжилсэн. Туршилтын явцад гарсан бүх үр дүнг CSV файлд хадгалж, параметрийн тохиргоо болон завсрын мэдээллүүдийг лог файлд бичсэн нь туршилтыг дахин давтах болон үр дүнг баталгаажуулах боломжийг бүрдүүлсэн.

Ерөнхийд нь дүгнэвэл, энэхүү судалгаанд хийсэн туршилтууд нь ижил өгөгдөл, ижил үнэлгээний шалгуур болон стандартчилсан орчинд гүйцэтгэгдсэн тул embedding болон загваруудын гүйцэтгэлийг бодитойгоор харьцуулах боломж олгосон бөгөөд дараагийн хэсэгт эдгээр туршилтуудаас гарсан үр дүнг дэлгэрэнгүй тайлбарлан дүн шинжилгээ хийсэн.
# 4. Үр дүн
### 4.1 TF-IDF embedding – Logistic Regression загварын туршилтын үр дүн

| C параметр | Accuracy (n-gram) | Precision | Recall | F1-score | Accuracy (uni-gram) | Precision | Recall | F1-score |
|-----------|------------------|-----------|--------|----------|---------------------|-----------|--------|----------|
| 0.0001 | 0.8765 | 0.8616 | 0.8993 | 0.8800 | 0.8593 | 0.8490 | 0.8765 | 0.8625 |
| 0.001 | 0.8679 | 0.8568 | 0.8858 | 0.8710 | 0.8503 | 0.8429 | 0.8638 | 0.8532 |
| 0.005 | 0.8637 | 0.8543 | 0.8794 | 0.8666 | 0.8432 | 0.8371 | 0.8552 | 0.8460 |
| 0.01 | 0.8628 | 0.8531 | 0.8791 | 0.8659 | 0.8405 | 0.8354 | 0.8510 | 0.8431 |
| 0.05 | 0.8609 | 0.8523 | 0.8759 | 0.8638 | 0.8383 | 0.8332 | 0.8491 | 0.8411 |
| 0.1 | 0.8583 | 0.8517 | 0.8703 | 0.8609 | 0.8369 | 0.8318 | 0.8476 | 0.8396 |
| 0.5 | 0.8573 | 0.8485 | 0.8727 | 0.8604 | 0.8417 | 0.8366 | 0.8523 | 0.8444 |
| 1 | 0.8565 | 0.8458 | 0.8746 | 0.8599 | 0.8421 | 0.8371 | 0.8526 | 0.8448 |
| 2 | 0.8561 | 0.8431 | 0.8777 | 0.8601 | 0.8417 | 0.8371 | 0.8515 | 0.8442 |
| 5 | 0.8555 | 0.8416 | 0.8787 | 0.8597 | 0.8406 | 0.8367 | 0.8494 | 0.8430 |
| 10 | 0.8553 | 0.8409 | 0.8791 | 0.8595 | 0.8406 | 0.8366 | 0.8497 | 0.8430 |
| 20 | 0.8549 | 0.8401 | 0.8793 | 0.8592 | 0.8408 | 0.8367 | 0.8501 | 0.8432 |
| 50 | 0.8548 | 0.8398 | 0.8796 | 0.8592 | 0.8407 | 0.8365 | 0.8499 | 0.8431 |
| 100 | 0.8548 | 0.8398 | 0.8796 | 0.8592 | 0.8404 | 0.8362 | 0.8498 | 0.8429 |
| 200 | 0.8548 | 0.8398 | 0.8796 | 0.8592 | 0.8403 | 0.8362 | 0.8497 | 0.8428 |
| 300 | 0.8548 | 0.8398 | 0.8796 | 0.8592 | 0.8403 | 0.8362 | 0.8497 | 0.8428 |
| 500 | 0.8547 | 0.8397 | 0.8796 | 0.8592 | 0.8403 | 0.8362 | 0.8497 | 0.8428 |
| 700 | 0.8547 | 0.8396 | 0.8796 | 0.8591 | 0.8403 | 0.8362 | 0.8497 | 0.8428 |
| 900 | 0.8547 | 0.8396 | 0.8796 | 0.8591 | 0.8403 | 0.8362 | 0.8497 | 0.8428 |
| 1000 | 0.8547 | 0.8396 | 0.8796 | 0.8591 | 0.8404 | 0.8362 | 0.8498 | 0.8429 |

### 4.2 TF-IDF embedding – Random Forest загварын туршилтын үр дүн

| n_estimators | depth | Accuracy (uni) | Precision | Recall | F1-score | Accuracy (n) | Precision | Recall | F1-score |
|-------------|-------|---------------|-----------|--------|----------|--------------|-----------|--------|----------|
| 50 | 5 | 0.7819 | 0.7409 | 0.8719 | 0.8011 | 0.7939 | 0.7464 | 0.8948 | 0.8139 |
| 50 | 10 | 0.8079 | 0.7765 | 0.8693 | 0.8202 | 0.8014 | 0.7702 | 0.8636 | 0.8142 |
| 50 | 15 | 0.8187 | 0.7945 | 0.8636 | 0.8276 | 0.8131 | 0.7818 | 0.8727 | 0.8247 |
| 50 | 20 | 0.8218 | 0.8031 | 0.8562 | 0.8288 | 0.8259 | 0.8069 | 0.8604 | 0.8327 |
| 100 | 5 | 0.8064 | 0.7618 | 0.8964 | 0.8235 | 0.8084 | 0.7654 | 0.8937 | 0.8246 |
| 100 | 10 | 0.8231 | 0.7883 | 0.8874 | 0.8349 | 0.8215 | 0.7819 | 0.8957 | 0.8349 |
| 100 | 15 | 0.8266 | 0.7991 | 0.8761 | 0.8358 | 0.8317 | 0.8006 | 0.8867 | 0.8415 |
| 100 | 20 | 0.8353 | 0.8167 | 0.8678 | 0.8415 | 0.8346 | 0.8104 | 0.8769 | 0.8423 |
| 150 | 5 | 0.8079 | 0.7603 | 0.9035 | 0.8257 | 0.8109 | 0.7622 | 0.9086 | 0.8289 |
| 150 | 10 | 0.8280 | 0.7943 | 0.8888 | 0.8389 | 0.8261 | 0.7874 | 0.8972 | 0.8387 |
| 150 | 15 | 0.8328 | 0.8039 | 0.8838 | 0.8419 | 0.8345 | 0.8037 | 0.8888 | 0.8441 |
| 150 | 20 | 0.8367 | 0.8151 | 0.8742 | 0.8436 | 0.8361 | 0.8118 | 0.8783 | 0.8437 |
| 200 | 5 | 0.8121 | 0.7655 | 0.9039 | 0.8290 | 0.8114 | 0.7615 | 0.9112 | 0.8296 |
| 200 | 10 | 0.8269 | 0.7923 | 0.8896 | 0.8381 | 0.8293 | 0.7885 | 0.9038 | 0.8422 |
| 200 | 15 | 0.8356 | 0.8095 | 0.8810 | 0.8437 | 0.8348 | 0.8032 | 0.8903 | 0.8445 |
| 200 | 20 | 0.8400 | 0.8161 | 0.8810 | 0.8473 | 0.8408 | 0.8141 | 0.8865 | 0.8487 |
| 300 | 5 | 0.8208 | 0.7736 | 0.9109 | 0.8367 | 0.8141 | 0.7622 | 0.9173 | 0.8326 |
| 300 | 10 | 0.8312 | 0.7971 | 0.8922 | 0.8419 | 0.8358 | 0.7982 | 0.9025 | 0.8471 |
| 300 | 15 | 0.8386 | 0.8110 | 0.8862 | 0.8469 | 0.8400 | 0.8080 | 0.8952 | 0.8494 |
| 300 | 20 | 0.8387 | 0.8161 | 0.8776 | 0.8457 | 0.8441 | 0.8175 | 0.8890 | 0.8517 |

### 4.3 TF-IDF embedding – AdaBoost загварын туршилтын үр дүн

| n_estimators | Learning rate | Accuracy (uni) | Precision | Recall | F1-score | Accuracy (n) | Precision | Recall | F1-score |
|-------------|---------------|----------------|-----------|--------|----------|--------------|-----------|--------|----------|
| 50 | 0.01 | 0.5915 | 0.5576 | 0.9289 | 0.6962 | 0.5924 | 0.5582 | 0.9285 | 0.6966 |
| 50 | 0.05 | 0.6447 | 0.5989 | 0.8919 | 0.7166 | 0.6449 | 0.5994 | 0.8899 | 0.7163 |
| 50 | 0.1 | 0.6446 | 0.5987 | 0.8936 | 0.7170 | 0.6445 | 0.5985 | 0.8940 | 0.7170 |
| 50 | 0.5 | 0.7005 | 0.6465 | 0.8949 | 0.7506 | 0.6943 | 0.6421 | 0.8887 | 0.7455 |
| 100 | 0.01 | 0.5916 | 0.5576 | 0.9289 | 0.6962 | 0.5911 | 0.5570 | 0.9315 | 0.6965 |
| 100 | 0.05 | 0.6447 | 0.5987 | 0.8935 | 0.7170 | 0.6445 | 0.5985 | 0.8940 | 0.7170 |
| 100 | 0.1 | 0.6651 | 0.6159 | 0.8903 | 0.7281 | 0.6649 | 0.6158 | 0.8902 | 0.7280 |
| 100 | 0.5 | 0.7239 | 0.6735 | 0.8775 | 0.7620 | 0.7261 | 0.6754 | 0.8793 | 0.7639 |
| 150 | 0.01 | 0.6186 | 0.5787 | 0.9210 | 0.7093 | 0.6175 | 0.5776 | 0.9234 | 0.7092 |
| 150 | 0.05 | 0.6520 | 0.6049 | 0.8924 | 0.7210 | 0.6516 | 0.6046 | 0.8923 | 0.7208 |
| 150 | 0.1 | 0.6663 | 0.6170 | 0.8898 | 0.7287 | 0.6681 | 0.6181 | 0.8931 | 0.7306 |
| 150 | 0.5 | 0.7407 | 0.6915 | 0.8765 | 0.7730 | 0.7463 | 0.7007 | 0.8663 | 0.7748 |
| 200 | 0.01 | 0.6401 | 0.5943 | 0.9014 | 0.7162 | 0.6449 | 0.5994 | 0.8899 | 0.7163 |
| 200 | 0.05 | 0.6587 | 0.6106 | 0.8910 | 0.7246 | 0.6585 | 0.6105 | 0.8908 | 0.7244 |
| 200 | 0.1 | 0.6757 | 0.6250 | 0.8914 | 0.7347 | 0.6745 | 0.6241 | 0.8904 | 0.7338 |
| 200 | 0.5 | 0.7565 | 0.7100 | 0.8735 | 0.7833 | 0.7557 | 0.7095 | 0.8723 | 0.7825 |
| 300 | 0.01 | 0.6440 | 0.5980 | 0.8951 | 0.7170 | 0.6449 | 0.5994 | 0.8899 | 0.7163 |
| 300 | 0.05 | 0.6668 | 0.6177 | 0.8884 | 0.7287 | 0.6674 | 0.6179 | 0.8904 | 0.7295 |
| 300 | 0.1 | 0.6928 | 0.6409 | 0.8879 | 0.7444 | 0.6929 | 0.6405 | 0.8902 | 0.7449 |
| 300 | 0.5 | 0.7695 | 0.7292 | 0.8632 | 0.7905 | 0.7693 | 0.7277 | 0.8667 | 0.7911 |

### 4.4 TF-IDF embedding – LSTM загварын туршилтын үр дүн

| LSTM units | Accuracy (uni) | Precision | Recall | F1-score | Accuracy (n) | Precision | Recall | F1-score |
|-----------|----------------|-----------|--------|----------|--------------|-----------|--------|----------|
| 4 | 0.9145 | 0.9049 | 0.9277 | 0.9162 | 0.9339 | 0.9268 | 0.9432 | 0.9349 |
| 8 | 0.9298 | 0.9278 | 0.9333 | 0.9305 | 0.9461 | 0.9424 | 0.9512 | 0.9468 |
| 12 | 0.9404 | 0.9353 | 0.9472 | 0.9412 | 0.9564 | 0.9530 | 0.9608 | 0.9569 |
| 16 | 0.9475 | 0.9367 | 0.9608 | 0.9486 | 0.9613 | 0.9587 | 0.9647 | 0.9617 |
| 20 | 0.9527 | 0.9503 | 0.9562 | 0.9532 | 0.9660 | 0.9674 | 0.9651 | 0.9662 |
| 24 | 0.9562 | 0.9470 | 0.9672 | 0.9570 | 0.9702 | 0.9635 | 0.9779 | 0.9706 |
| 28 | 0.9570 | 0.9550 | 0.9599 | 0.9574 | 0.9722 | 0.9678 | 0.9774 | 0.9725 |
| 32 | 0.9617 | 0.9519 | 0.9731 | 0.9624 | 0.9757 | 0.9744 | 0.9775 | 0.9760 |
| 36 | 0.9633 | 0.9620 | 0.9653 | 0.9637 | 0.9773 | 0.9780 | 0.9770 | 0.9775 |
| 40 | 0.9641 | 0.9585 | 0.9709 | 0.9646 | 0.9803 | 0.9744 | 0.9868 | 0.9805 |
| 44 | 0.9674 | 0.9622 | 0.9735 | 0.9678 | 0.9821 | 0.9829 | 0.9815 | 0.9822 |
| 48 | 0.9694 | 0.9714 | 0.9677 | 0.9696 | 0.9829 | 0.9780 | 0.9884 | 0.9832 |
| 52 | 0.9700 | 0.9696 | 0.9709 | 0.9702 | 0.9831 | 0.9800 | 0.9865 | 0.9832 |
| 56 | 0.9711 | 0.9678 | 0.9750 | 0.9714 | 0.9848 | 0.9844 | 0.9854 | 0.9849 |
| 60 | 0.9728 | 0.9741 | 0.9718 | 0.9730 | 0.9859 | 0.9848 | 0.9873 | 0.9861 |
| 64 | 0.9731 | 0.9673 | 0.9796 | 0.9734 | 0.9859 | 0.9875 | 0.9844 | 0.9860 |
| 72 | 0.9751 | 0.9770 | 0.9735 | 0.9753 | 0.9876 | 0.9833 | 0.9922 | 0.9877 |
| 80 | 0.9763 | 0.9728 | 0.9803 | 0.9765 | 0.9887 | 0.9895 | 0.9880 | 0.9887 |
| 96 | 0.9795 | 0.9743 | 0.9852 | 0.9797 | 0.9916 | 0.9910 | 0.9923 | 0.9917 |
| 128 | 0.9834 | 0.9838 | 0.9832 | 0.9835 | 0.9939 | 0.9946 | 0.9933 | 0.9939 |

### 4.5 Word2Vec embedding – Logistic Regression загварын туршилтын үр дүн

### 4.5 Word2Vec embedding – Logistic Regression загварын туршилтын үр дүн

| C параметр | Accuracy (CBOW) | Precision | Recall | F1-score | Accuracy (Skip-gram) | Precision | Recall | F1-score |
|-----------|------------------|-----------|--------|----------|----------------------|-----------|--------|----------|
| 0.0001 | 0.7909 | 0.7810 | 0.8130 | 0.7967 | 0.8163 | 0.8074 | 0.8346 | 0.8207 |
| 0.001 | 0.8290 | 0.8212 | 0.8445 | 0.8327 | 0.8489 | 0.8442 | 0.8585 | 0.8513 |
| 0.005 | 0.8365 | 0.8299 | 0.8498 | 0.8397 | 0.8549 | 0.8516 | 0.8622 | 0.8569 |
| 0.01 | 0.8377 | 0.8315 | 0.8501 | 0.8407 | 0.8553 | 0.8521 | 0.8626 | 0.8573 |
| 0.05 | 0.8379 | 0.8323 | 0.8493 | 0.8407 | 0.8563 | 0.8531 | 0.8636 | 0.8583 |
| 0.1 | 0.8367 | 0.8316 | 0.8474 | 0.8394 | 0.8567 | 0.8537 | 0.8636 | 0.8586 |
| 0.5 | 0.8361 | 0.8307 | 0.8473 | 0.8389 | 0.8575 | 0.8544 | 0.8645 | 0.8594 |
| 1 | 0.8360 | 0.8306 | 0.8473 | 0.8389 | 0.8575 | 0.8544 | 0.8646 | 0.8595 |
| 2 | 0.8365 | 0.8310 | 0.8478 | 0.8393 | 0.8577 | 0.8544 | 0.8649 | 0.8596 |
| 5 | 0.8366 | 0.8311 | 0.8480 | 0.8395 | 0.8574 | 0.8543 | 0.8645 | 0.8593 |
| 10 | 0.8364 | 0.8309 | 0.8478 | 0.8393 | 0.8577 | 0.8544 | 0.8649 | 0.8596 |
| 20 | 0.8364 | 0.8309 | 0.8478 | 0.8393 | 0.8577 | 0.8546 | 0.8649 | 0.8597 |
| 50 | 0.8364 | 0.8309 | 0.8478 | 0.8393 | 0.8577 | 0.8546 | 0.8649 | 0.8597 |
| 100 | 0.8364 | 0.8309 | 0.8478 | 0.8393 | 0.8577 | 0.8546 | 0.8649 | 0.8597 |
| 200 | 0.8364 | 0.8309 | 0.8478 | 0.8393 | 0.8577 | 0.8546 | 0.8649 | 0.8597 |
| 300 | 0.8364 | 0.8309 | 0.8478 | 0.8393 | 0.8577 | 0.8546 | 0.8649 | 0.8597 |
| 500 | 0.8364 | 0.8309 | 0.8478 | 0.8393 | 0.8577 | 0.8546 | 0.8649 | 0.8597 |
| 700 | 0.8364 | 0.8309 | 0.8478 | 0.8393 | 0.8577 | 0.8546 | 0.8649 | 0.8597 |
| 900 | 0.8364 | 0.8309 | 0.8478 | 0.8393 | 0.8577 | 0.8546 | 0.8649 | 0.8597 |
| 1000 | 0.8364 | 0.8309 | 0.8478 | 0.8393 | 0.8577 | 0.8546 | 0.8649 | 0.8597 |

### 4.6 Word2Vec embedding – Random Forest загварын туршилтын үр дүн

| n_estimators | depth | Accuracy (CBOW) | Precision | Recall | F1-score | Accuracy (Skip-gram) | Precision | Recall | F1-score |
|-------------|-------|-----------------|-----------|--------|----------|----------------------|-----------|--------|----------|
| 50 | 5 | 0.7702 | 0.7681 | 0.7791 | 0.7736 | 0.7940 | 0.7833 | 0.8173 | 0.7999 |
| 50 | 10 | 0.7941 | 0.7870 | 0.8108 | 0.7987 | 0.8186 | 0.8060 | 0.8428 | 0.8240 |
| 50 | 15 | 0.7961 | 0.7882 | 0.8141 | 0.8009 | 0.8219 | 0.8102 | 0.8443 | 0.8269 |
| 50 | 20 | 0.7917 | 0.7806 | 0.8159 | 0.7979 | 0.8205 | 0.8074 | 0.8456 | 0.8260 |
| 100 | 5 | 0.7714 | 0.7698 | 0.7794 | 0.7745 | 0.7996 | 0.7896 | 0.8211 | 0.8050 |
| 100 | 10 | 0.7977 | 0.7918 | 0.8121 | 0.8018 | 0.8227 | 0.8127 | 0.8424 | 0.8272 |
| 100 | 15 | 0.7969 | 0.7843 | 0.8235 | 0.8034 | 0.8265 | 0.8122 | 0.8527 | 0.8320 |
| 100 | 20 | 0.7970 | 0.7837 | 0.8248 | 0.8037 | 0.8273 | 0.8110 | 0.8570 | 0.8333 |
| 150 | 5 | 0.7729 | 0.7708 | 0.7818 | 0.7763 | 0.8001 | 0.7893 | 0.8229 | 0.8058 |
| 150 | 10 | 0.7980 | 0.7903 | 0.8154 | 0.8027 | 0.8230 | 0.8117 | 0.8446 | 0.8278 |
| 150 | 15 | 0.8023 | 0.7900 | 0.8274 | 0.8083 | 0.8285 | 0.8131 | 0.8564 | 0.8342 |
| 150 | 20 | 0.8015 | 0.7887 | 0.8278 | 0.8078 | 0.8312 | 0.8139 | 0.8621 | 0.8373 |
| 200 | 5 | 0.7741 | 0.7713 | 0.7840 | 0.7776 | 0.8001 | 0.7899 | 0.8218 | 0.8055 |
| 200 | 10 | 0.7981 | 0.7926 | 0.8117 | 0.8020 | 0.8249 | 0.8144 | 0.8452 | 0.8295 |
| 200 | 15 | 0.8042 | 0.7928 | 0.8277 | 0.8099 | 0.8277 | 0.8127 | 0.8552 | 0.8334 |
| 200 | 20 | 0.8056 | 0.7917 | 0.8334 | 0.8120 | 0.8284 | 0.8106 | 0.8605 | 0.8348 |
| 300 | 5 | 0.7721 | 0.7694 | 0.7821 | 0.7757 | 0.8014 | 0.7902 | 0.8248 | 0.8071 |
| 300 | 10 | 0.8005 | 0.7941 | 0.8154 | 0.8046 | 0.8268 | 0.8159 | 0.8474 | 0.8314 |
| 300 | 15 | 0.8035 | 0.7928 | 0.8259 | 0.8090 | 0.8282 | 0.8142 | 0.8539 | 0.8336 |
| 300 | 20 | 0.8030 | 0.7884 | 0.8323 | 0.8098 | 0.8281 | 0.8100 | 0.8607 | 0.8346 |

### 4.7 Word2Vec embedding – AdaBoost загварын туршилтын үр дүн

| Embedding | n_estimators | Learning rate | Accuracy | Precision | Recall | F1-score |
|----------|--------------|---------------|----------|-----------|--------|----------|
| CBOW | 50 | 0.01 | 0.6752 | 0.6737 | 0.6954 | 0.6820 |
| CBOW | 50 | 0.05 | 0.7292 | 0.7609 | 0.6746 | 0.7151 |
| CBOW | 50 | 0.1 | 0.7417 | 0.7816 | 0.6765 | 0.7252 |
| CBOW | 50 | 0.5 | 0.7841 | 0.7877 | 0.7823 | 0.7850 |
| CBOW | 100 | 0.01 | 0.7085 | 0.7299 | 0.6697 | 0.6982 |
| CBOW | 100 | 0.05 | 0.7454 | 0.7798 | 0.6894 | 0.7318 |
| CBOW | 100 | 0.1 | 0.7603 | 0.7857 | 0.7211 | 0.7520 |
| CBOW | 100 | 0.5 | 0.7994 | 0.7987 | 0.8047 | 0.8017 |
| CBOW | 150 | 0.01 | 0.7209 | 0.7449 | 0.6786 | 0.7101 |
| CBOW | 150 | 0.05 | 0.7515 | 0.7834 | 0.7004 | 0.7396 |
| CBOW | 150 | 0.1 | 0.7721 | 0.7862 | 0.7522 | 0.7688 |
| CBOW | 150 | 0.5 | 0.8076 | 0.8049 | 0.8159 | 0.8104 |
| CBOW | 200 | 0.01 | 0.7246 | 0.7535 | 0.6738 | 0.7114 |
| CBOW | 200 | 0.05 | 0.7619 | 0.7859 | 0.7249 | 0.7541 |
| CBOW | 200 | 0.1 | 0.7807 | 0.7917 | 0.7664 | 0.7788 |
| CBOW | 200 | 0.5 | 0.8099 | 0.8071 | 0.8182 | 0.8126 |
| CBOW | 300 | 0.01 | 0.7333 | 0.7710 | 0.6696 | 0.7167 |
| CBOW | 300 | 0.05 | 0.7721 | 0.7854 | 0.7537 | 0.7692 |
| CBOW | 300 | 0.1 | 0.7901 | 0.7932 | 0.7889 | 0.7911 |
| CBOW | 300 | 0.5 | 0.8143 | 0.8112 | 0.8231 | 0.8171 |
| Skip-gram | 50 | 0.01 | 0.7173 | 0.7264 | 0.7049 | 0.7153 |
| Skip-gram | 50 | 0.05 | 0.7568 | 0.7844 | 0.7136 | 0.7472 |
| Skip-gram | 50 | 0.1 | 0.7739 | 0.8090 | 0.7216 | 0.7627 |
| Skip-gram | 50 | 0.5 | 0.8120 | 0.8210 | 0.8016 | 0.8112 |
| Skip-gram | 100 | 0.01 | 0.7331 | 0.7469 | 0.7118 | 0.7288 |
| Skip-gram | 100 | 0.05 | 0.7754 | 0.8062 | 0.7295 | 0.7659 |
| Skip-gram | 100 | 0.1 | 0.7951 | 0.8120 | 0.7721 | 0.7915 |
| Skip-gram | 100 | 0.5 | 0.8267 | 0.8285 | 0.8273 | 0.8279 |
| Skip-gram | 150 | 0.01 | 0.7411 | 0.7589 | 0.7128 | 0.7350 |
| Skip-gram | 150 | 0.05 | 0.7855 | 0.8074 | 0.7543 | 0.7799 |
| Skip-gram | 150 | 0.1 | 0.8043 | 0.8151 | 0.7911 | 0.8029 |
| Skip-gram | 150 | 0.5 | 0.8314 | 0.8303 | 0.8363 | 0.8333 |
| Skip-gram | 200 | 0.01 | 0.7497 | 0.7720 | 0.7142 | 0.7419 |
| Skip-gram | 200 | 0.05 | 0.7941 | 0.8131 | 0.7679 | 0.7898 |
| Skip-gram | 200 | 0.1 | 0.8097 | 0.8180 | 0.8004 | 0.8091 |
| Skip-gram | 200 | 0.5 | 0.8343 | 0.8334 | 0.8390 | 0.8361 |
| Skip-gram | 300 | 0.01 | 0.7615 | 0.7935 | 0.7121 | 0.7505 |
| Skip-gram | 300 | 0.05 | 0.8033 | 0.8133 | 0.7913 | 0.8021 |
| Skip-gram | 300 | 0.1 | 0.8173 | 0.8212 | 0.8149 | 0.8180 |
| Skip-gram | 300 | 0.5 | 0.8376 | 0.8363 | 0.8427 | 0.8394 |

### 4.8 Word2Vec embedding – LSTM загварын туршилтын үр дүн

| Embedding | LSTM units | Accuracy | Precision | Recall | F1-score |
|----------|------------|----------|-----------|--------|----------|
| W2V_CBOW | 4 | 0.8186 | 0.7960 | 0.8604 | 0.8270 |
| W2V_CBOW | 8 | 0.8267 | 0.8057 | 0.8645 | 0.8341 |
| W2V_CBOW | 12 | 0.8292 | 0.8152 | 0.8547 | 0.8345 |
| W2V_CBOW | 16 | 0.8325 | 0.8347 | 0.8325 | 0.8336 |
| W2V_CBOW | 20 | 0.8321 | 0.8324 | 0.8347 | 0.8336 |
| W2V_CBOW | 24 | 0.8323 | 0.8383 | 0.8267 | 0.8324 |
| W2V_CBOW | 28 | 0.8343 | 0.8154 | 0.8674 | 0.8406 |
| W2V_CBOW | 32 | 0.8317 | 0.8041 | 0.8804 | 0.8405 |
| W2V_CBOW | 36 | 0.8349 | 0.8133 | 0.8724 | 0.8419 |
| W2V_CBOW | 40 | 0.8299 | 0.8513 | 0.8024 | 0.8262 |
| W2V_CBOW | 44 | 0.8327 | 0.8516 | 0.8089 | 0.8297 |
| W2V_CBOW | 48 | 0.8339 | 0.8397 | 0.8284 | 0.8340 |
| W2V_CBOW | 52 | 0.8357 | 0.8378 | 0.8358 | 0.8368 |
| W2V_CBOW | 56 | 0.8357 | 0.8330 | 0.8429 | 0.8379 |
| W2V_CBOW | 64 | 0.8364 | 0.8121 | 0.8785 | 0.8440 |
| W2V_CBOW | 80 | 0.8359 | 0.8173 | 0.8685 | 0.8421 |
| W2V_CBOW | 128 | 0.8357 | 0.8119 | 0.8769 | 0.8432 |
| W2V_SKIPGRAM | 4 | 0.7947 | 0.7929 | 0.8019 | 0.7974 |
| W2V_SKIPGRAM | 8 | 0.8050 | 0.8013 | 0.8150 | 0.8081 |
| W2V_SKIPGRAM | 12 | 0.8147 | 0.7809 | 0.8789 | 0.8270 |
| W2V_SKIPGRAM | 16 | 0.8189 | 0.7817 | 0.8887 | 0.8318 |
| W2V_SKIPGRAM | 20 | 0.8294 | 0.8085 | 0.8666 | 0.8366 |
| W2V_SKIPGRAM | 24 | 0.8326 | 0.8103 | 0.8719 | 0.8400 |
| W2V_SKIPGRAM | 36 | 0.8393 | 0.8253 | 0.8640 | 0.8442 |
| W2V_SKIPGRAM | 48 | 0.8421 | 0.8365 | 0.8535 | 0.8449 |
| W2V_SKIPGRAM | 56 | 0.8373 | 0.7973 | 0.9080 | 0.8490 |
| W2V_SKIPGRAM | 80 | 0.8471 | 0.8367 | 0.8653 | 0.8508 |
| W2V_SKIPGRAM | 96 | 0.8482 | 0.8379 | 0.8662 | 0.8518 |
| W2V_SKIPGRAM | 128 | 0.8475 | 0.8451 | 0.8538 | 0.8494 |

### 4.9 BERT / ALBERT embedding – ангиллын загваруудын туршилтын үр дүн

| Run | Model | C | Accuracy | Precision | Recall | F1-score |
|----|--------------------|-----|----------|-----------|--------|----------|
| 1 | Logistic Regression | 1.0 | 0.7849 | 0.7819 | 0.7902 | 0.7860 |
| 1 | Random Forest | 1.0 | 0.7163 | 0.7201 | 0.7076 | 0.7138 |
| 1 | AdaBoost | 1.0 | 0.7250 | 0.7268 | 0.7210 | 0.7239 |
| 1 | LSTM | 1.0 | 0.7645 | 0.7604 | 0.7724 | 0.7663 |
| 2 | Logistic Regression | 0.5 | 0.7849 | 0.7825 | 0.7892 | 0.7858 |
| 2 | Random Forest | 0.5 | 0.7177 | 0.7221 | 0.7078 | 0.7149 |
| 2 | AdaBoost | 0.5 | 0.7250 | 0.7268 | 0.7210 | 0.7239 |
| 2 | LSTM | 0.5 | 0.7563 | 0.8012 | 0.6818 | 0.7367 |
| 3 | Logistic Regression | 2.0 | 0.7847 | 0.7816 | 0.7902 | 0.7859 |
| 3 | Random Forest | 2.0 | 0.7176 | 0.7223 | 0.7070 | 0.7146 |
| 3 | AdaBoost | 2.0 | 0.7250 | 0.7268 | 0.7210 | 0.7239 |
| 3 | LSTM | 2.0 | 0.7616 | 0.7772 | 0.7334 | 0.7547 |
| 4 | Logistic Regression | 5.0 | 0.7835 | 0.7801 | 0.7896 | 0.7848 |
| 4 | Random Forest | 5.0 | 0.7204 | 0.7245 | 0.7112 | 0.7178 |
| 4 | AdaBoost | 5.0 | 0.7250 | 0.7268 | 0.7210 | 0.7239 |
| 4 | LSTM | 5.0 | 0.7542 | 0.7953 | 0.6846 | 0.7358 |
| 5 | Logistic Regression | 10.0 | 0.7832 | 0.7800 | 0.7890 | 0.7845 |
| 5 | Random Forest | 10.0 | 0.7188 | 0.7242 | 0.7068 | 0.7154 |
| 5 | AdaBoost | 10.0 | 0.7250 | 0.7268 | 0.7210 | 0.7239 |
| 5 | LSTM | 10.0 | 0.7642 | 0.7628 | 0.7668 | 0.7648 |
| 6 | Logistic Regression | 0.1 | 0.7845 | 0.7838 | 0.7858 | 0.7848 |
| 6 | Random Forest | 0.1 | 0.7074 | 0.7127 | 0.6950 | 0.7037 |
| 6 | AdaBoost | 0.1 | 0.7250 | 0.7268 | 0.7210 | 0.7239 |
| 6 | LSTM | 0.1 | 0.7563 | 0.7857 | 0.7048 | 0.7431 |
| 7 | Logistic Regression | 0.05 | 0.7824 | 0.7818 | 0.7834 | 0.7826 |
| 7 | Random Forest | 0.05 | 0.7173 | 0.7221 | 0.7064 | 0.7142 |
| 7 | AdaBoost | 0.05 | 0.7250 | 0.7268 | 0.7210 | 0.7239 |
| 7 | LSTM | 0.05 | 0.7618 | 0.7416 | 0.8036 | 0.7714 |
| 8 | Logistic Regression | 0.01 | 0.7703 | 0.7719 | 0.7674 | 0.7696 |
| 8 | Random Forest | 0.01 | 0.7191 | 0.7241 | 0.7080 | 0.7159 |
| 8 | AdaBoost | 0.01 | 0.7250 | 0.7268 | 0.7210 | 0.7239 |
| 8 | LSTM | 0.01 | 0.7551 | 0.7156 | 0.8466 | 0.7756 |

### 4.10 BERT base embedding – ангиллын загваруудын туршилтын үр дүн

| Run | Model | C | Accuracy | Precision | Recall | F1-score |
|----|--------------------|-----|----------|-----------|--------|----------|
| 1 | Logistic Regression | 0.5 | 0.8080 | 0.8097 | 0.8052 | 0.8075 |
| 1 | Random Forest | 0.5 | 0.7409 | 0.7422 | 0.7382 | 0.7402 |
| 1 | AdaBoost | 0.5 | 0.7376 | 0.7488 | 0.7150 | 0.7315 |
| 1 | LSTM | 0.5 | 0.7845 | 0.7671 | 0.8170 | 0.7913 |
| 2 | Logistic Regression | 1.0 | 0.8075 | 0.8093 | 0.8046 | 0.8069 |
| 2 | Random Forest | 1.0 | 0.7382 | 0.7372 | 0.7404 | 0.7388 |
| 2 | AdaBoost | 1.0 | 0.7376 | 0.7488 | 0.7150 | 0.7315 |
| 2 | LSTM | 1.0 | 0.7869 | 0.7951 | 0.7730 | 0.7839 |
| 3 | Logistic Regression | 5.0 | 0.8072 | 0.8088 | 0.8046 | 0.8067 |
| 3 | Random Forest | 5.0 | 0.7367 | 0.7380 | 0.7340 | 0.7360 |
| 3 | AdaBoost | 5.0 | 0.7376 | 0.7488 | 0.7150 | 0.7315 |
| 3 | LSTM | 5.0 | 0.7804 | 0.8204 | 0.7180 | 0.7658 |
| 4 | Logistic Regression | 10.0 | 0.8069 | 0.8083 | 0.8046 | 0.8065 |
| 4 | Random Forest | 10.0 | 0.7410 | 0.7431 | 0.7366 | 0.7399 |
| 4 | AdaBoost | 10.0 | 0.7376 | 0.7488 | 0.7150 | 0.7315 |
| 4 | LSTM | 10.0 | 0.7612 | 0.8588 | 0.6252 | 0.7236 |
| 5 | Logistic Regression | 2.0 | 0.8070 | 0.8087 | 0.8042 | 0.8065 |
| 5 | Random Forest | 2.0 | 0.7412 | 0.7429 | 0.7378 | 0.7403 |
| 5 | AdaBoost | 2.0 | 0.7376 | 0.7488 | 0.7150 | 0.7315 |
| 5 | LSTM | 2.0 | 0.7652 | 0.7131 | 0.8874 | 0.7908 |
| 6 | Logistic Regression | 0.1 | 0.8099 | 0.8123 | 0.8060 | 0.8092 |
| 6 | Random Forest | 0.1 | 0.7408 | 0.7416 | 0.7392 | 0.7404 |
| 6 | AdaBoost | 0.1 | 0.7376 | 0.7488 | 0.7150 | 0.7315 |
| 6 | LSTM | 0.1 | 0.7842 | 0.7586 | 0.8336 | 0.7944 |
| 7 | Logistic Regression | 0.05 | 0.8104 | 0.8137 | 0.8052 | 0.8094 |
| 7 | Random Forest | 0.05 | 0.7356 | 0.7345 | 0.7380 | 0.7362 |
| 7 | AdaBoost | 0.05 | 0.7376 | 0.7488 | 0.7150 | 0.7315 |
| 7 | LSTM | 0.05 | 0.7737 | 0.8192 | 0.7024 | 0.7563 |
| 8 | Logistic Regression | 0.01 | 0.8094 | 0.8115 | 0.8060 | 0.8087 |
| 8 | Random Forest | 0.01 | 0.7405 | 0.7439 | 0.7336 | 0.7387 |
| 8 | AdaBoost | 0.01 | 0.7376 | 0.7488 | 0.7150 | 0.7315 |
| 8 | LSTM | 0.01 | 0.7811 | 0.7528 | 0.8370 | 0.7927 |

### 4.10 Hate Speech датасет дээрх BERT embedding загваруудын туршилтын үр дүн

| Run | Model | C | Accuracy | Precision | Recall | F1-score |
|----|--------------------|-----|----------|-----------|--------|----------|
| 1 | Logistic Regression | 0.05 | 0.8178 | 0.8157 | 0.8212 | 0.8184 |
| 1 | Random Forest | 0.05 | 0.7605 | 0.7550 | 0.7712 | 0.7630 |
| 1 | AdaBoost | 0.05 | 0.7616 | 0.7649 | 0.7554 | 0.7601 |
| 1 | LSTM | 0.05 | 0.8022 | 0.7730 | 0.8556 | 0.8122 |
| 2 | Logistic Regression | 0.1 | 0.8178 | 0.8155 | 0.8214 | 0.8185 |
| 2 | Random Forest | 0.1 | 0.7643 | 0.7585 | 0.7756 | 0.7669 |
| 2 | AdaBoost | 0.1 | 0.7616 | 0.7649 | 0.7554 | 0.7601 |
| 2 | LSTM | 0.1 | 0.7982 | 0.8372 | 0.7404 | 0.7858 |
| 3 | Logistic Regression | 0.5 | 0.8191 | 0.8178 | 0.8212 | 0.8195 |
| 3 | Random Forest | 0.5 | 0.7665 | 0.7610 | 0.7770 | 0.7689 |
| 3 | AdaBoost | 0.5 | 0.7616 | 0.7649 | 0.7554 | 0.7601 |
| 3 | LSTM | 0.5 | 0.8014 | 0.7634 | 0.8736 | 0.8148 |
| 4 | Logistic Regression | 5.0 | 0.8183 | 0.8160 | 0.8220 | 0.8190 |
| 4 | Random Forest | 5.0 | 0.7640 | 0.7568 | 0.7780 | 0.7673 |
| 4 | AdaBoost | 5.0 | 0.7616 | 0.7649 | 0.7554 | 0.7601 |
| 4 | LSTM | 5.0 | 0.8076 | 0.8072 | 0.8082 | 0.8077 |
| 5 | Logistic Regression | 2.0 | 0.8187 | 0.8169 | 0.8216 | 0.8192 |
| 5 | Random Forest | 2.0 | 0.7592 | 0.7538 | 0.7698 | 0.7617 |
| 5 | AdaBoost | 2.0 | 0.7616 | 0.7649 | 0.7554 | 0.7601 |
| 5 | LSTM | 2.0 | 0.8058 | 0.7969 | 0.8208 | 0.8087 |
| 6 | Logistic Regression | 10.0 | 0.8184 | 0.8161 | 0.8220 | 0.8191 |
| 6 | Random Forest | 10.0 | 0.7634 | 0.7569 | 0.7760 | 0.7663 |
| 6 | AdaBoost | 10.0 | 0.7616 | 0.7649 | 0.7554 | 0.7601 |
| 6 | LSTM | 10.0 | 0.8097 | 0.8066 | 0.8148 | 0.8107 |
| 7 | Logistic Regression | 1.0 | 0.8198 | 0.8180 | 0.8226 | 0.8203 |
| 7 | Random Forest | 1.0 | 0.7602 | 0.7521 | 0.7762 | 0.7640 |
| 7 | AdaBoost | 1.0 | 0.7616 | 0.7649 | 0.7554 | 0.7601 |
| 7 | LSTM | 1.0 | 0.8047 | 0.7803 | 0.8482 | 0.8128 |
| 8 | Logistic Regression | 0.01 | 0.8111 | 0.8094 | 0.8138 | 0.8116 |
| 8 | Random Forest | 0.01 | 0.7612 | 0.7546 | 0.7742 | 0.7643 |
| 8 | AdaBoost | 0.01 | 0.7616 | 0.7649 | 0.7554 | 0.7601 |
| 8 | LSTM | 0.01 | 0.8029 | 0.8272 | 0.7658 | 0.7953 |

### 4.11 Hate Speech датасет дээрх BERT robert embedding загваруудын туршилтын үр дүн

| Run | Model | C | Accuracy | Precision | Recall | F1-score |
|----|--------------------|-----|----------|-----------|--------|----------|
| 1 | Logistic Regression | 10.0 | 0.8423 | 0.8387 | 0.8476 | 0.8431 |
| 1 | Random Forest | 10.0 | 0.8071 | 0.8015 | 0.8164 | 0.8089 |
| 1 | AdaBoost | 10.0 | 0.8012 | 0.8106 | 0.7860 | 0.7981 |
| 1 | LSTM | 10.0 | 0.8242 | 0.7962 | 0.8714 | 0.8321 |
| 2 | Logistic Regression | 5.0 | 0.8411 | 0.8381 | 0.8456 | 0.8418 |
| 2 | Random Forest | 5.0 | 0.7984 | 0.7935 | 0.8068 | 0.8001 |
| 2 | AdaBoost | 5.0 | 0.8012 | 0.8106 | 0.7860 | 0.7981 |
| 2 | LSTM | 5.0 | 0.8277 | 0.8217 | 0.8370 | 0.8293 |
| 3 | Logistic Regression | 2.0 | 0.8385 | 0.8360 | 0.8422 | 0.8391 |
| 3 | Random Forest | 2.0 | 0.8067 | 0.7992 | 0.8192 | 0.8091 |
| 3 | AdaBoost | 2.0 | 0.8012 | 0.8106 | 0.7860 | 0.7981 |
| 3 | LSTM | 2.0 | 0.8264 | 0.8077 | 0.8568 | 0.8315 |
| 4 | Logistic Regression | 1.0 | 0.8374 | 0.8347 | 0.8414 | 0.8380 |
| 4 | Random Forest | 1.0 | 0.8054 | 0.8002 | 0.8140 | 0.8071 |
| 4 | AdaBoost | 1.0 | 0.8012 | 0.8106 | 0.7860 | 0.7981 |
| 4 | LSTM | 1.0 | 0.8236 | 0.7923 | 0.8772 | 0.8326 |
| 5 | Logistic Regression | 0.5 | 0.8342 | 0.8318 | 0.8378 | 0.8348 |
| 5 | Random Forest | 0.5 | 0.8076 | 0.8024 | 0.8162 | 0.8092 |
| 5 | AdaBoost | 0.5 | 0.8012 | 0.8106 | 0.7860 | 0.7981 |
| 5 | LSTM | 0.5 | 0.8253 | 0.8006 | 0.8664 | 0.8322 |
| 6 | Logistic Regression | 0.1 | 0.8290 | 0.8263 | 0.8332 | 0.8297 |
| 6 | Random Forest | 0.1 | 0.8029 | 0.7982 | 0.8108 | 0.8044 |
| 6 | AdaBoost | 0.1 | 0.8012 | 0.8106 | 0.7860 | 0.7981 |
| 6 | LSTM | 0.1 | 0.8253 | 0.8245 | 0.8266 | 0.8255 |
| 7 | Logistic Regression | 0.05 | 0.8228 | 0.8209 | 0.8258 | 0.8233 |
| 7 | Random Forest | 0.05 | 0.7997 | 0.7955 | 0.8068 | 0.8011 |
| 7 | AdaBoost | 0.05 | 0.8012 | 0.8106 | 0.7860 | 0.7981 |
| 7 | LSTM | 0.05 | 0.8247 | 0.8269 | 0.8214 | 0.8241 |
| 8 | Logistic Regression | 0.01 | 0.8079 | 0.8067 | 0.8098 | 0.8083 |
| 8 | Random Forest | 0.01 | 0.7997 | 0.7955 | 0.8068 | 0.8011 |
| 8 | AdaBoost | 0.01 | 0.8012 | 0.8106 | 0.7860 | 0.7981 |
| 8 | LSTM | 0.01 | 0.8212 | 0.8564 | 0.7718 | 0.8119 |


### 4.12 Hate Speech датасет дээрх BERT sbert embedding загваруудын туршилтын үр дүн

| Run | Model | C | Accuracy | Precision | Recall | F1-score |
|----|--------------------|-----|----------|-----------|--------|----------|
| 1 | Logistic Regression | 10.0 | 0.8290 | 0.8252 | 0.8348 | 0.8300 |
| 1 | Random Forest | 10.0 | 0.7824 | 0.7704 | 0.8046 | 0.7871 |
| 1 | AdaBoost | 10.0 | 0.7695 | 0.7674 | 0.7734 | 0.7704 |
| 1 | LSTM | 10.0 | 0.8129 | 0.8120 | 0.8144 | 0.8132 |
| 2 | Logistic Regression | 5.0 | 0.8288 | 0.8252 | 0.8344 | 0.8298 |
| 2 | Random Forest | 5.0 | 0.7763 | 0.7670 | 0.7938 | 0.7801 |
| 2 | AdaBoost | 5.0 | 0.7695 | 0.7674 | 0.7734 | 0.7704 |
| 2 | LSTM | 5.0 | 0.8122 | 0.8169 | 0.8048 | 0.8108 |
| 3 | Logistic Regression | 2.0 | 0.8274 | 0.8239 | 0.8328 | 0.8283 |
| 3 | Random Forest | 2.0 | 0.7813 | 0.7690 | 0.8042 | 0.7862 |
| 3 | AdaBoost | 2.0 | 0.7695 | 0.7674 | 0.7734 | 0.7704 |
| 3 | LSTM | 2.0 | 0.8057 | 0.7712 | 0.8694 | 0.8173 |
| 4 | Logistic Regression | 1.0 | 0.8247 | 0.8210 | 0.8304 | 0.8257 |
| 4 | Random Forest | 1.0 | 0.7852 | 0.7730 | 0.8076 | 0.7899 |
| 4 | AdaBoost | 1.0 | 0.7695 | 0.7674 | 0.7734 | 0.7704 |
| 4 | LSTM | 1.0 | 0.8094 | 0.7847 | 0.8528 | 0.8173 |
| 5 | Logistic Regression | 0.5 | 0.8218 | 0.8184 | 0.8272 | 0.8228 |
| 5 | Random Forest | 0.5 | 0.7815 | 0.7685 | 0.8058 | 0.7867 |
| 5 | AdaBoost | 0.5 | 0.7695 | 0.7674 | 0.7734 | 0.7704 |
| 5 | LSTM | 0.5 | 0.8132 | 0.8041 | 0.8282 | 0.8160 |
| 6 | Logistic Regression | 0.1 | 0.8143 | 0.8097 | 0.8218 | 0.8157 |
| 6 | Random Forest | 0.1 | 0.7793 | 0.7663 | 0.8038 | 0.7846 |
| 6 | AdaBoost | 0.1 | 0.7695 | 0.7674 | 0.7734 | 0.7704 |
| 6 | LSTM | 0.1 | 0.8109 | 0.8254 | 0.7886 | 0.8066 |
| 7 | Logistic Regression | 0.05 | 0.8120 | 0.8073 | 0.8196 | 0.8134 |
| 7 | Random Forest | 0.05 | 0.7827 | 0.7734 | 0.7998 | 0.7864 |
| 7 | AdaBoost | 0.05 | 0.7695 | 0.7674 | 0.7734 | 0.7704 |
| 7 | LSTM | 0.05 | 0.8124 | 0.8096 | 0.8170 | 0.8133 |
| 8 | Logistic Regression | 0.01 | 0.7982 | 0.7947 | 0.8042 | 0.7994 |
| 8 | Random Forest | 0.01 | 0.7795 | 0.7696 | 0.7978 | 0.7835 |
| 8 | AdaBoost | 0.01 | 0.7695 | 0.7674 | 0.7734 | 0.7704 |
| 8 | LSTM | 0.01 | 0.8136 | 0.7971 | 0.8414 | 0.8186 |

# 5. Ерөнхий дүгнэлт
Ерөнхийд нь авч үзвэл, энэхүү судалгааны үр дүнгээс текст ангиллын асуудалд ашиглах embedding болон загварыг сонгохдоо өгөгдлийн шинж чанар, асуудлын төрөл, тооцооллын зардлыг хамтад нь харгалзан үзэх шаардлагатай болох нь харагдаж байна. ЭнгЭнэхүү судалгааны ажлаар киноны сэтгэгдэл болон hate speech ангиллын текст өгөгдөл дээр sentiment болон хандлагын ангилал хийх зорилгоор уламжлалт статистик аргачлал, тархмал үгийн векторууд болон орчин үеийн контекстэд суурилсан embedding загваруудыг ашиглан олон төрлийн машин сургалтын болон гүн сургалтын загваруудын гүйцэтгэлийг харьцуулан судаллаа. Судалгаанд IMDB sentiment analysis болон hate speech датасетуудыг ашиглаж, өгөгдлийн урьдчилсан боловсруулалт, онцлог шинжийн дүрслэл (embedding), ангиллын загвар, үнэлгээний аргачлал гэсэн үндсэн үе шатуудын хүрээнд туршилтуудыг системтэйгээр явуулсан.
Туршилтын үр дүнгээс харахад уламжлалт TF-IDF embedding нь ялангуяа unigram болон n-gram тохиргоондоо Logistic Regression болон LSTM загвартай хослох үед өндөр гүйцэтгэл үзүүлж, IMDB датасет дээр 0.98–0.99 хүртэлх accuracy болон F1-score-т хүрсэн нь текстийн гадаргуугийн шинж чанар тод илэрдэг sentiment analysis асуудалд энэхүү арга үр дүнтэй болохыг баталж байна. Үүний зэрэгцээ Word2Vec embedding-үүдийн хувьд Skip-gram загвар нь CBOW-оос илүү гүйцэтгэл үзүүлсэн бөгөөд энэ нь ховор үгс болон семантик холбоог илүү сайн барьж чаддагаараа тайлбарлагдана. Гэсэн хэдий ч Word2Vec дээр суурилсан загваруудын гүйцэтгэл нь TF-IDF болон трансформер суурьтай embedding-үүдээс нийтлэг байдлаар доогуур байв.
Контекстэд суурилсан BERT, RoBERTa болон SBERT embedding-үүдийг ашигласан туршилтууд нь илүү нарийн семантик мэдээлэл шаардсан hate speech ангиллын асуудалд илүү тогтвортой бөгөөд өндөр гүйцэтгэлтэй байсныг харуулсан. Ялангуяа SBERT embedding-тэй Logistic Regression загвар нь өндөр хэмжээст өгүүлбэрийн векторыг энгийн шугаман ангилагчтай үр дүнтэй хослуулж, өндөр accuracy болон F1-score-ыг тогтвортой гаргасан нь анхаарал татаж байна. LSTM загвар нь зарим тохиолдолд recall үзүүлэлтээр давуу талтай байсан ч параметрийн мэдрэмж өндөртэй, сургалтын тогтвортой байдал харьцангуй сул байв.
ийн sentiment analysis асуудалд TF-IDF + Logistic Regression зэрэг хөнгөн загварууд өндөр үр ашигтай байхад, контекст болон далд утга илүү чухал hate speech зэрэг асуудалд трансформер суурьтай embedding-үүд илүү тохиромжтой болохыг энэхүү судалгаа нотоллоо. Цаашдын судалгаанд fine-tuning хийсэн трансформер загварууд, олон хэлний датасет болон илүү гүн бүтэцтэй neural network-үүдийг ашиглан гүйцэтгэлийг цаашид сайжруулах боломжтой гэж дүгнэж байна.



# Ашигласан материал
[1]https://arxiv.org/pdf/1512.08183.pdf
[2] https://arxiv.org/abs/1408.5882
[3]https://arxiv.org/abs/1412.1058
[4]https://arxiv.org/abs/1511.01432
[5]https://arxiv.org/abs/1511.08630
[6]https://arxiv.org/abs/1509.01626
[7]https://arxiv.org/abs/1801.06146
[8]https://arxiv.org/abs/1810.04805
[9]https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf
[10]https://arxiv.org/abs/1606.02310


